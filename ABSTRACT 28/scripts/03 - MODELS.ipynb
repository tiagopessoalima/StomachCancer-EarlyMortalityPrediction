{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a54228",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81e6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "from constants import RANDOM_STATE\n",
    "from functions import best_features_set\n",
    "\n",
    "# deap imports\n",
    "from deap import creator, base, tools, algorithms\n",
    "\n",
    "# imbalanced-learn imports\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# joblib-related imports\n",
    "from joblib import dump\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, QuantileTransformer, RobustScaler, StandardScaler \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# scikit-optimize imports\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# standard Python imports\n",
    "import ast\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# additional settings\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500fc5db",
   "metadata": {},
   "source": [
    "# DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03530c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_evaluations = '../evaluations/'\n",
    "directory_models = '../models/'\n",
    "directory_plots = '../images/'\n",
    "\n",
    "for directory in [directory_evaluations, \n",
    "                  directory_models, \n",
    "                  directory_plots]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5f13f",
   "metadata": {},
   "source": [
    "# READ FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf6c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../dataset/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../dataset/y_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ce045",
   "metadata": {},
   "source": [
    "# IMBALANCE RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3083d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio of is 0.4\n"
     ]
    }
   ],
   "source": [
    "class_counts = y_train.value_counts()\n",
    "imb_ratio = round(class_counts.min() / class_counts.max() * 10) / 10\n",
    "print(f'Imbalance ratio of is {imb_ratio}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a529f67c",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dfb2d7",
   "metadata": {},
   "source": [
    "Generates a pipeline for machine learning models with optional data preprocessing steps such as normalization, imputation, and balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f95f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model, use_normalization=True, use_imputation=True, use_balancing=True, use_pca=True):\n",
    "    steps = [('normalization', None)] if use_normalization else []\n",
    "    steps += [('imputation', KNNImputer())] if use_imputation else []\n",
    "    steps += [('balancing', None)] if use_balancing else []\n",
    "    steps.append((model.__class__.__name__.lower(), model)) \n",
    "    return Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec57c6",
   "metadata": {},
   "source": [
    "- These are the normalization methods evaluated in this pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e3f15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_methods = [\n",
    "    MaxAbsScaler(),\n",
    "    MinMaxScaler(),\n",
    "    QuantileTransformer(),\n",
    "    RobustScaler(),\n",
    "    StandardScaler()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625d17b",
   "metadata": {},
   "source": [
    "- These are the balancing methods evaluated in this pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef8d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balancing_methods = [\n",
    "    RandomOverSampler(random_state=RANDOM_STATE),\n",
    "    RandomUnderSampler(random_state=RANDOM_STATE),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d29416",
   "metadata": {},
   "source": [
    "Defines a set of models along with their respective hyperparameter spaces for hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b2be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_settings = {\n",
    "    'normalization': Categorical(normalization_methods),\n",
    "    'imputation__n_neighbors': Integer(1, 10),\n",
    "    'imputation__weights': Categorical(['distance', 'uniform']),\n",
    "    'balancing': Categorical(balancing_methods),\n",
    "    'balancing__sampling_strategy': Real(imb_ratio, 1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d93be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_space = {\n",
    "    \n",
    "    'DT': {\n",
    "        'model': create_pipeline(DecisionTreeClassifier(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'decisiontreeclassifier__max_depth': Integer(3, 5),\n",
    "            'decisiontreeclassifier__min_samples_split': Integer(5, 10),\n",
    "            'decisiontreeclassifier__min_samples_leaf': Integer(1, 5),\n",
    "            'decisiontreeclassifier__criterion': Categorical(['gini', 'entropy']),\n",
    "            'decisiontreeclassifier__ccp_alpha': Real(0.0, 0.1),\n",
    "            **common_settings\n",
    "        } \n",
    "    },\n",
    "\n",
    "    'GB': {\n",
    "        'model': create_pipeline(GradientBoostingClassifier(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'gradientboostingclassifier__n_estimators': Integer(50, 500),\n",
    "            'gradientboostingclassifier__learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "            'gradientboostingclassifier__max_depth': Integer(1, 10),\n",
    "            'gradientboostingclassifier__min_samples_split': Integer(2, 20),  \n",
    "            'gradientboostingclassifier__min_samples_leaf': Integer(1, 20),  \n",
    "            'gradientboostingclassifier__subsample': Real(0.5, 1.0, 'log-uniform'), \n",
    "            'gradientboostingclassifier__loss': Categorical(['deviance', 'exponential']), \n",
    "            **common_settings\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'LR': {\n",
    "        'model': create_pipeline(LogisticRegression(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'logisticregression__C': Real(0.0001, 1000, 'log-uniform'),\n",
    "            'logisticregression__max_iter': Integer(200, 2000),\n",
    "            'logisticregression__solver': Categorical(['liblinear', 'sag', 'saga']),\n",
    "            'logisticregression__class_weight': Categorical(['balanced', None]),\n",
    "            'logisticregression__tol': Real(0.0001, 0.001),\n",
    "            **common_settings\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'MLP': {\n",
    "        'model': create_pipeline(MLPClassifier(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'mlpclassifier__hidden_layer_sizes': Integer(2, 16),\n",
    "            'mlpclassifier__activation': Categorical(['logistic','tanh', 'relu']),\n",
    "            'mlpclassifier__learning_rate': Categorical(['constant', 'adaptive']),\n",
    "            'mlpclassifier__learning_rate_init': Real(0.001, 0.1, 'log-uniform'),\n",
    "            'mlpclassifier__max_iter': Integer(200, 2000),\n",
    "            'mlpclassifier__solver': Categorical(['sgd', 'adam']),\n",
    "            'mlpclassifier__momentum': Real(0.1, 0.9, 'log-uniform'),\n",
    "            **common_settings\n",
    "        }\n",
    "    },\n",
    "  \n",
    "    'NB': {\n",
    "        'model': create_pipeline(GaussianNB()),\n",
    "        'space': {\n",
    "            **common_settings\n",
    "        }\n",
    "    },\n",
    "        \n",
    "    'RF': {\n",
    "        'model': create_pipeline(RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'randomforestclassifier__n_estimators': Integer(50,500),\n",
    "            'randomforestclassifier__max_depth': Integer(3, 10),\n",
    "            'randomforestclassifier__min_samples_split': Integer(2, 10),\n",
    "            'randomforestclassifier__min_samples_leaf': Integer(1, 5),\n",
    "            'randomforestclassifier__criterion': Categorical(['gini', 'entropy']),\n",
    "            'randomforestclassifier__max_samples': Real(0.5, 1.0, 'log-uniform'),\n",
    "            'randomforestclassifier__class_weight': Categorical(['balanced', 'balanced_subsample']),\n",
    "            **common_settings\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'SVM': {\n",
    "        'model': create_pipeline(SVC(probability=True, random_state=RANDOM_STATE)),\n",
    "        'space': {\n",
    "            'svc__kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "            'svc__gamma': Real(0.001, 1000),\n",
    "            'svc__degree': Integer(2, 5),\n",
    "            'svc__coef0': Real(0.0001, 1, 'log-uniform'),\n",
    "            'svc__C': Real(0.001, 1000),\n",
    "            'svc__tol': Real(0.00001, 0.1, 'log-uniform'),\n",
    "            'svc__max_iter': Integer(200, 2000),\n",
    "            'svc__class_weight': Categorical([None, 'balanced']),\n",
    "            **common_settings\n",
    "        }\n",
    "    }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95325e20",
   "metadata": {},
   "source": [
    "Implements Bayesian optimization for hyperparameter tuning using the BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223bf613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_search(model, space, refit=True):\n",
    "    bs = BayesSearchCV(\n",
    "        model, space, n_iter=10, refit=refit,  \n",
    "        cv=RepeatedStratifiedKFold(random_state=RANDOM_STATE), \n",
    "        random_state=RANDOM_STATE,  \n",
    "        scoring='f1'\n",
    "    )\n",
    "    return bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5ca1c",
   "metadata": {},
   "source": [
    "# FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "088d575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['KATZ', 'MNA-SF', 'Hemoglobin', 'Leukocyte', 'Advanced Staging'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c4e7a",
   "metadata": {},
   "source": [
    "# SAVE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b38de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: ['KATZ', 'MNA-SF', 'Hemoglobin', 'Leukocyte', 'Advanced Staging'] -> 0.522645938311102\n",
      "GB: ['KATZ', 'MNA-SF', 'Hemoglobin', 'Leukocyte', 'Advanced Staging'] -> 0.6120094968521406\n",
      "LR: ['KATZ', 'MNA-SF', 'Hemoglobin', 'Leukocyte', 'Advanced Staging'] -> 0.6403565174076009\n",
      "MLP: ['KATZ', 'MNA-SF', 'Hemoglobin', 'Leukocyte', 'Advanced Staging'] -> 0.6418989826822643\n",
      "NB: ['KATZ', 'MNA-SF', 'Hemoglobin', 'Leukocyte', 'Advanced Staging'] -> 0.6356302161890397\n",
      "RF: ['KATZ', 'MNA-SF', 'Hemoglobin', 'Leukocyte', 'Advanced Staging'] -> 0.6412872514482422\n",
      "SVM: ['KATZ', 'MNA-SF', 'Hemoglobin', 'Leukocyte', 'Advanced Staging'] -> 0.500292261847424\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_space:\n",
    "    model_opt = bayes_search(\n",
    "        model_space[model_name]['model'],\n",
    "        model_space[model_name]['space'])\n",
    "    model_opt.fit(X_train.loc[:,features],y_train)\n",
    "    print(f'{model_name}: {features} -> {model_opt.best_score_}')\n",
    "    model_path = f'{directory_models}/{model_name}.joblib'\n",
    "    dump(model_opt.best_estimator_, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
